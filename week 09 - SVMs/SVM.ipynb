{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10cc31d-1a87-418d-bdbb-3d040cec68ba",
   "metadata": {},
   "source": [
    "# üß† Support Vector Machines (SVM) - Complete Guide with Titanic Dataset\n",
    "\n",
    "---\n",
    "\n",
    "## üî∑ What is SVM?\n",
    "\n",
    "Support Vector Machine (SVM) is a **supervised learning algorithm** used for **classification** and **regression**.\n",
    "\n",
    "SVM finds the **optimal hyperplane** that separates classes with the **maximum margin**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Intuition\n",
    "\n",
    "SVM aims to:\n",
    "\n",
    "- Separate classes using a **hyperplane**\n",
    "- **Maximize the margin** between the nearest data points of each class\n",
    "- Use only the **support vectors** (the closest points) to define the decision boundary\n",
    "\n",
    "A larger margin usually means better generalization to new data.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Mathematics of Linear SVM\n",
    "\n",
    "For binary classification with labels $y_i \\in \\{-1, 1\\}$ and data points $x_i \\in \\mathbb{R}^n$, the primal form of the optimization problem is:\n",
    "\n",
    "$\n",
    "\\min_{w, b} \\ \\frac{1}{2} \\|w\\|^2\n",
    "$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$\n",
    "y_i (w \\cdot x_i + b) \\geq 1 \\quad \\text{for all } i\n",
    "$\n",
    "\n",
    "- $w$ is the normal vector to the hyperplane\n",
    "- $b$ is the bias term\n",
    "- The margin is $\\frac{2}{\\|w\\|}$\n",
    "\n",
    "If the data is not linearly separable, we introduce **slack variables** $\\xi_i$ and a **regularization parameter** $C$:\n",
    "\n",
    "$\n",
    "\\min_{w, b, \\xi} \\ \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^n \\xi_i\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "## üåê Nonlinear Data: The Kernel Trick\n",
    "\n",
    "To deal with nonlinear boundaries, SVM uses **kernels** to project data into a higher-dimensional space.\n",
    "\n",
    "The kernel function $K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j)$ computes inner products in that space **without explicitly transforming the data**.\n",
    "\n",
    "Common kernels:\n",
    "\n",
    "- **Linear**: $K(x, x') = x^T x'$\n",
    "- **Polynomial**: $K(x, x') = (x^T x' + 1)^d$\n",
    "- **RBF (Gaussian)**: $K(x, x') = \\exp(-\\gamma \\|x - x'\\|^2)$\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Parameters in SVM\n",
    "\n",
    "| Parameter | Description |\n",
    "|----------|-------------|\n",
    "| `C` | Regularization parameter: trade-off between margin width and misclassification |\n",
    "| `kernel` | Defines the kernel type (e.g., `'linear'`, `'rbf'`) |\n",
    "| `gamma` | Controls kernel complexity in RBF and polynomial kernels |\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ Real-World Example: Predicting Titanic Survival with SVM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42b66c-d547-449e-a4a1-f4705338b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üì¶ 1. Load and Explore Data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a44b5-c4ac-4417-93ac-37fdff5d290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffb742-fbc3-4ea9-a714-a49628e20998",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üßπ 2. Preprocess the Data\n",
    "# Encode categorical features\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embarked'] = df['embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af0c7e-0bfe-4dd9-a263-de1e337ee9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ü§ñ 3. Train and Evaluate SVM Model\n",
    "model = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test_scaled, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826a133-a439-4575-8fca-0cf1b93d522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üõ†Ô∏è 4. Hyperparameter Tuning with Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4e431-d2c4-4934-b81e-4ccab0390ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_estimator(grid, X_test_scaled, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
